Map<K,V> - interface
	AbstractMap<K,V>
		HashMap<K,V>
		ConcurrentHashMap<K,V>

Collection<E> - interface
	Set<E> - interface
		AbstractCollection<Set>		
			AbstractSet<E>
				HashSet<E>


				
				

Map<K,V>
	Dictionary<K,V>
		HashTable<K,V>
			Properties				
		
Iterable<T> - interface		
	Collection<E> - interface	
		CollectionView<K,V,K>		
			KeySetView<K,V>


Iterator<E> - interface		

List<T> - interface
	AbstractList<T>
		ArrayList<T>

ServletRequest
	HttpServletRequest - abstract interface
	
	
KStreamGroup.reduce(reducer, <Windows<W>>windows, storename)

KStreamAggProcessorSupplier<K, Windowed<K>, V, V>
	KStreamWindowReduce<K, V, W extends Window>

java.io.FileOutputStream
	getChannel()
	close()
java.io.FileOutputStream
	lock()
	close()
java.nio.channels.FileLock	
	release()

Collections.unmodifiableMap  返回一个只读视图

java.net.HttpURLConnection 生成一个请求到web server， 但是它的socket连接是多个请求共享的，调用close会结束请求，但是不会断开连接。调用disconnect会在连接空闲时断开他。
	
Callable<GenericDataModel> callable = new Callable<GenericDataModel>(){};
FutureTask<GenericDataModel> futureTask = new FutureTask<>(callable);
ExecutorService executorService = Executors.newFixedThreadPool(1);
executorService.submit(futureTask);

定期执行的ExecutorService
ScheduledExecutorService updateScheduler = Executors.newScheduledThreadPool(1);

缓存空闲的线程，若空闲超过60秒则移出。若无可用线程则新建。
ExecutorService es = Executors.newCachedThreadPool();

ClassLoader.getSystemClassLoader() vs Class.forName

String byteString = new String(byte[] inputByteArray)


java.util.concurrent.locks.ReentrantLock

Java 内置锁就是用 synchronized, 可以锁对象，锁类。
wait 方法是停止当前线程，释放锁，等待别的线程唤醒。
notifyAll 方法是唤醒正在等待该对象锁的线程，使其继续运行。

Java 中的显式锁，就是在命名空间java.util.concurrent.lock中提供的各类锁
参考 Java 博客精编 #3
Java 博客精编
1. Java中的锁 http://www.importnew.com/19472.html
2. Java中对象的大小 http://www.importnew.com/19172.html + 
http://www.cnblogs.com/magialmoon/p/3757767.html
3. Java中的ReentrantLock和synchronized两种锁定机制的对比 http://www.cnblogs.com/cxzdgs/p/5746895.html
4. Java GC: http://www.importnew.com/1993.html
5. JVM：如何分析线程堆栈 http://www.oschina.net/translate/jvm-how-to-analyze-thread-dump?cmp&p=2
6. Java 内存屏障：http://www.cnblogs.com/chenyangyao/p/5269622.html
＋http://ifeve.com/disruptor-memory-barrier/


Kafka stream: 
offset commit failure 怎么解决。 核心是consumer问题. consumer 调用poll方法来进行心跳。若超过一定时间(max.poll.interval.ms)则认为consumer挂掉了，会把consumer的partition分配给别的consumer(group repartition)，这时候调用commitSync有可能会发生offset commit failure。
这是安全机制，保证只有group中活着的consumer能够commit offset。  
通常使用consumer，是在一个while循环里面，调用poll接收多个数据(在kafkastream中最多为max.poll.records=1000,consumer默认最多500)，然后处理这些数据，如果一下子接收的数据太多，处理不过来，就可能导致这种group repartition发生，进而导致offset commit failure.



Consumer Client Re-Design: Kafka consumer 重新设计过， 尽量减少对 zookeeper 的依赖，更简单的client jar 包， 中心化的 co-ordination. 允许手动的 partion, offset 管理
https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Client+Re-Design
先发送 ConsumerMetadataRequest 到任意一台broker来获取Coordinator 信息。
consumer 组管理分两个阶段：１收集组成员信息，并选出组长２组长同步组成员状态
步骤：
1 各个组员发 JoinGroupRequest 给Coordinator。 Coordinator返回组长信息
2 各个组员发 SyncGroupRequest 给Coordinator。 Coordinator返回组长信息

JMX, JMap, JAAS, GC log

kafka delete consumer group tool:kafka-consumer-groups.sh. This will delete a consumer group. ./kafka-consumer-groups.sh --zookeeper <zookeeper_url> --delete --group <group-name>

zookeeper purge data：zkCleanup.sh
java -cp zookeeper.jar:log4j.jar:conf org.apache.zookeeper.server.PurgeTxnLog <dataDir> <snapDir> -n <count>

Hash 算法详解
http://www.cnblogs.com/xiohao/p/4389672.html

https://www.cnblogs.com/doit8791/p/4209442.html


JIT编译完的结果是否缓存起来了？在什么位置？
字节码存在方法区（perm generation），它是不会被清空的，因为可能会多次用到它来解释，或者需要多次编译它。它有一个指针指向编译结果，初始结果是NULL